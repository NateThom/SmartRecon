{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import gc\n",
    "from socket import gethostname\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "import utils"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Garbage collector: collected 0 objects.\n"
     ]
    }
   ],
   "source": [
    "dataset, name_of_current_data = utils.get_dataset()\n",
    "dataset.reset_index(drop=True, inplace=True)\n",
    "collected = gc.collect()\n",
    "print(\"Garbage collector: collected %d objects.\" % (collected))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Total samples in FlexHash-plug-accum_1024-win_5-combo_4-cleaned: 152009 ***\n",
      "*** Samples for device: plug-1 in FlexHash-plug-accum_1024-win_5-combo_4-cleaned: 16415 (0.10798702708392266%) ***\n",
      "*** Samples for device: plug-2 in FlexHash-plug-accum_1024-win_5-combo_4-cleaned: 15192 (0.09994145083514792%) ***\n",
      "*** Samples for device: plug-3 in FlexHash-plug-accum_1024-win_5-combo_4-cleaned: 17811 (0.11717069384049629%) ***\n",
      "*** Samples for device: plug-4 in FlexHash-plug-accum_1024-win_5-combo_4-cleaned: 21993 (0.14468222276312587%) ***\n",
      "*** Samples for device: plug-5 in FlexHash-plug-accum_1024-win_5-combo_4-cleaned: 19964 (0.1313343288884211%) ***\n",
      "*** Samples for device: plug-6 in FlexHash-plug-accum_1024-win_5-combo_4-cleaned: 14779 (0.09722450644369741%) ***\n",
      "*** Samples for device: plug-7 in FlexHash-plug-accum_1024-win_5-combo_4-cleaned: 30078 (0.19786986296864%) ***\n",
      "*** Samples for device: plug-8 in FlexHash-plug-accum_1024-win_5-combo_4-cleaned: 15777 (0.10378990717654876%) ***\n",
      "Garbage collector: collected 0 objects.\n",
      "*** Dataset Loaded ***\n"
     ]
    }
   ],
   "source": [
    "print(f\"*** Total samples in {name_of_current_data}: {len(dataset.index)} ***\")\n",
    "for device_name in sorted(dataset[\"class\"].unique()):\n",
    "    num_samples = len((dataset[dataset[\"class\"] == device_name]).index)\n",
    "    print(\n",
    "        f\"*** Samples for device: {device_name} in {name_of_current_data}: {num_samples} ({num_samples/dataset.shape[0]}%) ***\"\n",
    "    )\n",
    "\n",
    "# x is the entire dataframe except for the class column\n",
    "x = dataset.drop([\"class\"], axis=1)\n",
    "\n",
    "# y_original is an unaltered list of all values in the class column\n",
    "y_original = dataset[\"class\"].values.tolist()\n",
    "\n",
    "# y is a dataframe of only the class column and the values have been converted to numeric representation\n",
    "y = dataset[\"class\"]\n",
    "counter = 0\n",
    "y_temp = dataset[\"class\"].tolist()\n",
    "for unique_value in sorted(y.unique()):\n",
    "    for index, value in enumerate(y):\n",
    "        if value == unique_value:\n",
    "            y_temp[index] = counter\n",
    "    counter += 1\n",
    "dataset[\"class\"] = y_temp\n",
    "y = dataset[\"class\"]\n",
    "labels_numeric = dataset[\"class\"].unique()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x.values, y.values, test_size=0.8, stratify=y.values\n",
    ")\n",
    "\n",
    "\n",
    "names = list(range(x_train.shape[1]))\n",
    "train_dataset_df = pd.DataFrame(x_train, columns=names)\n",
    "train_dataset_df.insert(train_dataset_df.shape[1], \"class\", y_train)\n",
    "\n",
    "names = list(range(x_test.shape[1]))\n",
    "test_dataset_df = pd.DataFrame(x_test, columns=names)\n",
    "test_dataset_df.insert(test_dataset_df.shape[1], \"class\", y_test)\n",
    "\n",
    "del (\n",
    "    x,\n",
    "    y,\n",
    "    y_original,\n",
    "    y_temp,\n",
    "    labels_numeric,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_test,\n",
    "    y_test,\n",
    "    dataset,\n",
    "    names,\n",
    ")\n",
    "collected = gc.collect()\n",
    "print(\"Garbage collector: collected %d objects.\" % (collected))\n",
    "\n",
    "print(\"*** Dataset Loaded ***\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count    30401.000000\n",
      "mean         3.693497\n",
      "std          2.229232\n",
      "min          0.000000\n",
      "25%          2.000000\n",
      "50%          4.000000\n",
      "75%          6.000000\n",
      "max          7.000000\n",
      "Name: class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "model_save_path = f\"agModels-{name_of_current_data}_{gethostname()}\"\n",
    "\n",
    "train_dataset_td = TabularDataset(train_dataset_df)\n",
    "label = \"class\"\n",
    "print(\"Summary of class variable: \\n\", train_dataset_td[label].describe())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-FlexHash-plug-accum_1024-win_5-combo_4-cleaned-3_1\"\n",
      "Presets specified: ['medium_quality']\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (30401 samples, 136.09 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"agModels-FlexHash-plug-accum_1024-win_5-combo_4-cleaned-3_1/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.9\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #33~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Jan 30 17:03:34 UTC 2\n",
      "Train Data Rows:    30401\n",
      "Train Data Columns: 128\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t8 unique label values:  [0, 3, 2, 6, 7, 4, 1, 5]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 8\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18808.65 MB\n",
      "\tTrain Data (Original)  Memory Usage: 135.84 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('object', []) : 128 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 128 | ['0', '1', '2', '3', '4', ...]\n",
      "\t0.8s = Fit runtime\n",
      "\t128 features in original data used to generate 128 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 4.15 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.93s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_micro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.08223413703496596, Train Rows: 27901, Val Rows: 2500\n",
      "Excluded Model Types: ['NN_TORCH', 'FASTAI']\n",
      "\tFound 'NN_TORCH' model in hyperparameters, but 'NN_TORCH' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'FASTAI' model in hyperparameters, but 'FASTAI' is present in `excluded_model_types` and will be removed.\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\tNo valid features to train KNeighborsUnif... Skipping this model.\n",
      "Fitting model: KNeighborsDist ...\n",
      "\tNo valid features to train KNeighborsDist... Skipping this model.\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.6204\t = Validation score   (f1_micro)\n",
      "\t9.19s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.6164\t = Validation score   (f1_micro)\n",
      "\t7.63s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.5988\t = Validation score   (f1_micro)\n",
      "\t1.27s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.596\t = Validation score   (f1_micro)\n",
      "\t1.41s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(\n",
    "    eval_metric=\"f1_micro\", label=\"class\", path=model_save_path\n",
    ").fit(train_dataset_td, presets=\"best_quality\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = predictor.fit_summary(show_plot=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictor = TabularPredictor.load(model_save_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dataset_td = TabularDataset(test_dataset_df)\n",
    "y_test = test_dataset_td[label]\n",
    "test_data_noLabel = test_dataset_td.drop(columns=[label])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = predictor.predict(test_data_noLabel)\n",
    "perf = predictor.evaluate_predictions(\n",
    "    y_true=y_test, y_pred=y_pred, auxiliary_metrics=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "leaderboard_df = predictor.leaderboard(test_dataset_td, silent=True)\n",
    "leaderboard_df.to_csv(\n",
    "    f\"autogluon_leaderboard_{name_of_current_data}_{gethostname()}.csv\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_importance_df = predictor.feature_importance(test_dataset_td)\n",
    "feature_importance_df[\"p_value\"].mean()\n",
    "feature_importance_df[\"p_value\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
