{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset, name_of_current_data = utils.get_dataset()\n",
    "dataset.reset_index(drop=True, inplace=True)\n",
    "collected = gc.collect()\n",
    "print(\"Garbage collector: collected %d objects.\" % (collected))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Total samples in SimHash-cam-accum_1024-win_5-combo_4-cleaned: 322434 ***\n",
      "*** Samples for device: cam-1 in SimHash-cam-accum_1024-win_5-combo_4-cleaned: 40774 (0.12645688730096702%) ***\n",
      "*** Samples for device: cam-2 in SimHash-cam-accum_1024-win_5-combo_4-cleaned: 40506 (0.12562570944751483%) ***\n",
      "*** Samples for device: cam-3 in SimHash-cam-accum_1024-win_5-combo_4-cleaned: 40396 (0.12528455435841132%) ***\n",
      "*** Samples for device: cam-4 in SimHash-cam-accum_1024-win_5-combo_4-cleaned: 39520 (0.12256771928518705%) ***\n",
      "*** Samples for device: cam-5 in SimHash-cam-accum_1024-win_5-combo_4-cleaned: 40618 (0.12597306735642022%) ***\n",
      "*** Samples for device: cam-6 in SimHash-cam-accum_1024-win_5-combo_4-cleaned: 40446 (0.1254396248534584%) ***\n",
      "*** Samples for device: cam-7 in SimHash-cam-accum_1024-win_5-combo_4-cleaned: 40299 (0.12498371759802006%) ***\n",
      "*** Samples for device: cam-8 in SimHash-cam-accum_1024-win_5-combo_4-cleaned: 39875 (0.12366871980002109%) ***\n",
      "Garbage collector: collected 1429 objects.\n",
      "*** Dataset Loaded ***\n"
     ]
    }
   ],
   "source": [
    "print(f\"*** Total samples in {name_of_current_data}: {len(dataset.index)} ***\")\n",
    "for device_name in sorted(dataset[\"class\"].unique()):\n",
    "    num_samples = len((dataset[dataset[\"class\"] == device_name]).index)\n",
    "    print(f\"*** Samples for device: {device_name} in {name_of_current_data}: {num_samples} ({num_samples/dataset.shape[0]}%) ***\")\n",
    "\n",
    "# x is the entire dataframe except for the class column\n",
    "x = dataset.drop(['class'], axis=1)\n",
    "\n",
    "# y_original is an unaltered list of all values in the class column\n",
    "y_original = dataset['class'].values.tolist()\n",
    "\n",
    "# y is a dataframe of only the class column and the values have been converted to numeric representation\n",
    "y = dataset['class']\n",
    "counter = 0\n",
    "y_temp = dataset['class'].tolist()\n",
    "for unique_value in sorted(y.unique()):\n",
    "    for index, value in enumerate(y):\n",
    "        if value == unique_value:\n",
    "            y_temp[index] = counter\n",
    "    counter += 1\n",
    "dataset[\"class\"] = y_temp\n",
    "y = dataset['class']\n",
    "labels_numeric = dataset['class'].unique()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x.values, y.values, test_size=.2, stratify=y.values)\n",
    "\n",
    "\n",
    "names = list(range(x_train.shape[1]))\n",
    "train_dataset_df = pd.DataFrame(x_train, columns=names)\n",
    "train_dataset_df.insert(train_dataset_df.shape[1], \"class\", y_train)\n",
    "\n",
    "names = list(range(x_test.shape[1]))\n",
    "test_dataset_df = pd.DataFrame(x_test, columns=names)\n",
    "test_dataset_df.insert(test_dataset_df.shape[1], \"class\", y_test)\n",
    "\n",
    "del x, y, y_original, y_temp, labels_numeric, x_train, y_train, x_test, y_test, dataset, names\n",
    "collected = gc.collect()\n",
    "print(\"Garbage collector: collected %d objects.\" % (collected))\n",
    "\n",
    "print(\"*** Dataset Loaded ***\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count    257947.000000\n",
      "mean          3.490570\n",
      "std           2.292715\n",
      "min           0.000000\n",
      "25%           1.000000\n",
      "50%           4.000000\n",
      "75%           5.000000\n",
      "max           7.000000\n",
      "Name: class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "model_save_path=f\"agModels-{name_of_current_data}\"\n",
    "\n",
    "train_dataset_td = TabularDataset(train_dataset_df)\n",
    "label = \"class\"\n",
    "print(\"Summary of class variable: \\n\", train_dataset_td[label].describe())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-predictDevice\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (257947 samples, 1121.56 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"agModels-predictDevice/\"\n",
      "AutoGluon Version:  0.6.2\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #64-Ubuntu SMP Thu Jan 5 11:43:13 UTC 2023\n",
      "Train Data Rows:    257947\n",
      "Train Data Columns: 128\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\t8 unique label values:  [0, 3, 1, 6, 4, 7, 2, 5]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 8\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31062.88 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1119.5 MB (3.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('object', []) : 128 | ['0', '1', '2', '3', '4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 128 | ['0', '1', '2', '3', '4', ...]\n",
      "\t5.6s = Fit runtime\n",
      "\t128 features in original data used to generate 128 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 44.7 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 6.46s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded Model Types: ['NN_TORCH', 'FASTAI']\n",
      "\tFound 'NN_TORCH' model in hyperparameters, but 'NN_TORCH' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'FASTAI' model in hyperparameters, but 'FASTAI' is present in `excluded_model_types` and will be removed.\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\tNo valid features to train KNeighborsUnif_BAG_L1... Skipping this model.\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\tNo valid features to train KNeighborsDist_BAG_L1... Skipping this model.\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.122\t = Validation score   (accuracy)\n",
      "\t8.15s\t = Training   runtime\n",
      "\t0.78s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.12\t = Validation score   (accuracy)\n",
      "\t10.9s\t = Training   runtime\n",
      "\t0.71s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ...\n",
      "\t0.0223\t = Validation score   (accuracy)\n",
      "\t32.73s\t = Training   runtime\n",
      "\t11.26s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ...\n",
      "\t0.022\t = Validation score   (accuracy)\n",
      "\t31.67s\t = Training   runtime\n",
      "\t11.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tThe worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nthom/anaconda3/envs/autogluon/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/nthom/anaconda3/envs/autogluon/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/nthom/anaconda3/envs/autogluon/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 703, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/nthom/anaconda3/envs/autogluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 154, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/nthom/anaconda3/envs/autogluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 249, in _fit\n",
      "    self._fit_folds(X=X, y=y, model_base=model_base, X_pseudo=X_pseudo, y_pseudo=y_pseudo,\n",
      "  File \"/home/nthom/anaconda3/envs/autogluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 541, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/nthom/anaconda3/envs/autogluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 536, in after_all_folds_scheduled\n",
      "    raise processed_exception\n",
      "  File \"/home/nthom/anaconda3/envs/autogluon/lib/python3.9/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 504, in after_all_folds_scheduled\n",
      "    time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/home/nthom/anaconda3/envs/autogluon/lib/python3.9/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/nthom/anaconda3/envs/autogluon/lib/python3.9/site-packages/ray/_private/worker.py\", line 2282, in get\n",
      "    raise value\n",
      "ray.exceptions.WorkerCrashedError: The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ...\n",
      "\t0.0229\t = Validation score   (accuracy)\n",
      "\t23.03s\t = Training   runtime\n",
      "\t10.66s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ...\n",
      "\t0.022\t = Validation score   (accuracy)\n",
      "\t24.62s\t = Training   runtime\n",
      "\t11.04s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1293\t = Validation score   (accuracy)\n",
      "\t66.65s\t = Training   runtime\n",
      "\t3.29s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1095\t = Validation score   (accuracy)\n",
      "\t16.25s\t = Training   runtime\n",
      "\t0.76s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1293\t = Validation score   (accuracy)\n",
      "\t19.72s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Excluded Model Types: ['NN_TORCH', 'FASTAI']\n",
      "\tFound 'NN_TORCH' model in hyperparameters, but 'NN_TORCH' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'FASTAI' model in hyperparameters, but 'FASTAI' is present in `excluded_model_types` and will be removed.\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5959\t = Validation score   (accuracy)\n",
      "\t4004.6s\t = Training   runtime\n",
      "\t1785.71s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6063\t = Validation score   (accuracy)\n",
      "\t4337.73s\t = Training   runtime\n",
      "\t984.59s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ...\n",
      "\t0.3341\t = Validation score   (accuracy)\n",
      "\t37.75s\t = Training   runtime\n",
      "\t13.96s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ...\n",
      "\t0.3342\t = Validation score   (accuracy)\n",
      "\t56.6s\t = Training   runtime\n",
      "\t13.94s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3319\t = Validation score   (accuracy)\n",
      "\t109.03s\t = Training   runtime\n",
      "\t1.56s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ...\n",
      "\t0.334\t = Validation score   (accuracy)\n",
      "\t21.81s\t = Training   runtime\n",
      "\t13.59s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ...\n",
      "\t0.3356\t = Validation score   (accuracy)\n",
      "\t22.72s\t = Training   runtime\n",
      "\t13.87s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.526\t = Validation score   (accuracy)\n",
      "\t7937.64s\t = Training   runtime\n",
      "\t369.22s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.605\t = Validation score   (accuracy)\n",
      "\t3849.58s\t = Training   runtime\n",
      "\t1086.66s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.6159\t = Validation score   (accuracy)\n",
      "\t20.36s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 21171.0s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictDevice/\")\n"
     ]
    }
   ],
   "source": [
    "excluded_model_types = ['NN_TORCH', \"FASTAI\"]\n",
    "predictor = TabularPredictor(label=\"class\", path=model_save_path).fit(train_dataset_td, presets=\"best_quality\", num_gpus=1, excluded_model_types=excluded_model_types)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                      model  score_val  pred_time_val      fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       WeightedEnsemble_L3   0.615878    3906.586901  12426.258812                0.016966          20.355004            3       True         19\n",
      "1           LightGBM_BAG_L2   0.606303    1034.203860   4551.722049              984.593742        4337.725071            2       True         11\n",
      "2      LightGBMLarge_BAG_L2   0.604981    1136.267698   4063.576134             1086.657580        3849.579156            2       True         18\n",
      "3         LightGBMXT_BAG_L2   0.595917    1835.318613   4218.599582             1785.708495        4004.602603            2       True         10\n",
      "4            XGBoost_BAG_L2   0.525972     418.834451   8151.637550              369.224333        7937.640571            2       True         17\n",
      "5     ExtraTreesEntr_BAG_L2   0.335604      63.484051    236.716949               13.873933          22.719970            2       True         16\n",
      "6   RandomForestEntr_BAG_L2   0.334216      63.552885    270.593118               13.942767          56.596139            2       True         13\n",
      "7   RandomForestGini_BAG_L2   0.334092      63.569416    251.750515               13.959298          37.753536            2       True         12\n",
      "8     ExtraTreesGini_BAG_L2   0.333979      63.202251    235.806728               13.592133          21.809749            2       True         15\n",
      "9           CatBoost_BAG_L2   0.331909      51.169994    323.029238                1.559876         109.032259            2       True         14\n",
      "10           XGBoost_BAG_L1   0.129344       3.287505     66.646631                3.287505          66.646631            1       True          7\n",
      "11      WeightedEnsemble_L2   0.129344       3.302199     86.366539                0.014694          19.719908            2       True          9\n",
      "12        LightGBMXT_BAG_L1   0.121963       0.779001      8.151877                0.779001           8.151877            1       True          1\n",
      "13          LightGBM_BAG_L1   0.119982       0.708384     10.897408                0.708384          10.897408            1       True          2\n",
      "14     LightGBMLarge_BAG_L1   0.109484       0.763205     16.246541                0.763205          16.246541            1       True          8\n",
      "15    ExtraTreesGini_BAG_L1   0.022927      10.655664     23.029975               10.655664          23.029975            1       True          5\n",
      "16  RandomForestGini_BAG_L1   0.022268      11.258553     32.733199               11.258553          32.733199            1       True          3\n",
      "17    ExtraTreesEntr_BAG_L1   0.021970      11.036882     24.616698               11.036882          24.616698            1       True          6\n",
      "18  RandomForestEntr_BAG_L1   0.021962      11.120924     31.674650               11.120924          31.674650            1       True          4\n",
      "Number of models trained: 19\n",
      "Types of models trained:\n",
      "{'WeightedEnsembleModel', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_XGBoost'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) : 128 | ['0', '1', '2', '3', '4', ...]\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nthom/anaconda3/envs/autogluon/lib/python3.9/site-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary(show_plot=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "predictor = TabularPredictor.load(model_save_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "test_dataset_td = TabularDataset(test_dataset_df)\n",
    "y_test = test_dataset_td[label]\n",
    "test_data_noLabel = test_dataset_td.drop(columns=[label])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.325910648657869\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.325910648657869,\n",
      "    \"balanced_accuracy\": 0.32590317986445605,\n",
      "    \"mcc\": 0.22960156408034707\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data_noLabel)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "leaderboard_df = predictor.leaderboard(test_dataset_td, silent=True)\n",
    "leaderboard_df.to_csv(f\"autogluon_leaderboard_{name_of_current_data}.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127]\n",
      "Computing feature importance via permutation shuffling for 0 features using 5000 rows with 5 shuffle sets...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"128 required columns are missing from the provided dataset to transform using AutoMLPipelineFeatureGenerator. Missing columns: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127']\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/anaconda3/envs/autogluon/lib/python3.9/site-packages/autogluon/features/generators/abstract.py:329\u001B[0m, in \u001B[0;36mAbstractFeatureGenerator.transform\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(X\u001B[38;5;241m.\u001B[39mcolumns) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures_in:\n\u001B[1;32m    327\u001B[0m         \u001B[38;5;66;03m# It comes at a cost when making a copy of the DataFrame,\u001B[39;00m\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;66;03m# therefore, try avoid copying by checking the expected features first.\u001B[39;00m\n\u001B[0;32m--> 329\u001B[0m         X \u001B[38;5;241m=\u001B[39m \u001B[43mX\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeatures_in\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    330\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/autogluon/lib/python3.9/site-packages/pandas/core/frame.py:3811\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3810\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[0;32m-> 3811\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcolumns\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m   3813\u001B[0m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/autogluon/lib/python3.9/site-packages/pandas/core/indexes/base.py:6113\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[0;34m(self, key, axis_name)\u001B[0m\n\u001B[1;32m   6111\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[0;32m-> 6113\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   6115\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n",
      "File \u001B[0;32m~/anaconda3/envs/autogluon/lib/python3.9/site-packages/pandas/core/indexes/base.py:6173\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[0;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[1;32m   6172\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[0;32m-> 6173\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   6175\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n",
      "\u001B[0;31mKeyError\u001B[0m: \"None of [Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\\n       ...\\n       '118', '119', '120', '121', '122', '123', '124', '125', '126', '127'],\\n      dtype='object', length=128)] are in the [columns]\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m feature_importance_df \u001B[38;5;241m=\u001B[39m \u001B[43mpredictor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeature_importance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_dataset_td\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m feature_importance_df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mp_value\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mmean()\n\u001B[1;32m      3\u001B[0m feature_importance_df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mp_value\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/envs/autogluon/lib/python3.9/site-packages/autogluon/tabular/predictor/predictor.py:1955\u001B[0m, in \u001B[0;36mTabularPredictor.feature_importance\u001B[0;34m(self, data, model, features, feature_stage, subsample_size, time_limit, num_shuffle_sets, include_confidence_band, confidence_level, silent)\u001B[0m\n\u001B[1;32m   1952\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_shuffle_sets \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1953\u001B[0m     num_shuffle_sets \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m time_limit \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m5\u001B[39m\n\u001B[0;32m-> 1955\u001B[0m fi_df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_learner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_feature_importance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1956\u001B[0m \u001B[43m                                             \u001B[49m\u001B[43mfeature_stage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeature_stage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1957\u001B[0m \u001B[43m                                             \u001B[49m\u001B[43msubsample_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubsample_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtime_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1958\u001B[0m \u001B[43m                                             \u001B[49m\u001B[43mnum_shuffle_sets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_shuffle_sets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msilent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msilent\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1960\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m include_confidence_band:\n\u001B[1;32m   1961\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m confidence_level \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.5\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m confidence_level \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.0\u001B[39m:\n",
      "File \u001B[0;32m~/anaconda3/envs/autogluon/lib/python3.9/site-packages/autogluon/tabular/learner/abstract_learner.py:671\u001B[0m, in \u001B[0;36mAbstractTabularLearner.get_feature_importance\u001B[0;34m(self, model, X, y, features, feature_stage, subsample_size, silent, **kwargs)\u001B[0m\n\u001B[1;32m    668\u001B[0m         X \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39munused_features)\n\u001B[1;32m    670\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m feature_stage \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124moriginal\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 671\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_feature_importance_raw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubsample_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubsample_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform_func\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msilent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msilent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    672\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform_features(X)\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/autogluon/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py:2177\u001B[0m, in \u001B[0;36mAbstractTrainer._get_feature_importance_raw\u001B[0;34m(self, X, y, model, eval_metric, **kwargs)\u001B[0m\n\u001B[1;32m   2175\u001B[0m model: AbstractModel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mload_model(model)\n\u001B[1;32m   2176\u001B[0m predict_func_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(model\u001B[38;5;241m=\u001B[39mmodel)\n\u001B[0;32m-> 2177\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcompute_permutation_feature_importance\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2178\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpredict_func\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpredict_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpredict_func_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpredict_func_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_metric\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquantile_levels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquantile_levels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m   2179\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/autogluon/lib/python3.9/site-packages/autogluon/core/utils/utils.py:759\u001B[0m, in \u001B[0;36mcompute_permutation_feature_importance\u001B[0;34m(X, y, predict_func, eval_metric, features, subsample_size, num_shuffle_sets, predict_func_kwargs, transform_func, transform_func_kwargs, time_limit, silent, log_prefix, importance_as_list, random_state, **kwargs)\u001B[0m\n\u001B[1;32m    757\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m subsample \u001B[38;5;129;01mor\u001B[39;00m shuffle_repeat \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    758\u001B[0m     time_start_score \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m--> 759\u001B[0m     X_transformed \u001B[38;5;241m=\u001B[39m X \u001B[38;5;28;01mif\u001B[39;00m transform_func \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[43mtransform_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtransform_func_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    760\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m predict_func(X_transformed, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpredict_func_kwargs)\n\u001B[1;32m    761\u001B[0m     score_baseline \u001B[38;5;241m=\u001B[39m eval_metric(y, y_pred, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/autogluon/lib/python3.9/site-packages/autogluon/tabular/learner/abstract_learner.py:262\u001B[0m, in \u001B[0;36mAbstractTabularLearner.transform_features\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    260\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtransform_features\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m feature_generator \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_generators:\n\u001B[0;32m--> 262\u001B[0m         X \u001B[38;5;241m=\u001B[39m \u001B[43mfeature_generator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    263\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m X\n",
      "File \u001B[0;32m~/anaconda3/envs/autogluon/lib/python3.9/site-packages/autogluon/features/generators/abstract.py:335\u001B[0m, in \u001B[0;36mAbstractFeatureGenerator.transform\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    333\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m col \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m X\u001B[38;5;241m.\u001B[39mcolumns:\n\u001B[1;32m    334\u001B[0m             missing_cols\u001B[38;5;241m.\u001B[39mappend(col)\n\u001B[0;32m--> 335\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(missing_cols)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m required columns are missing from the provided dataset to transform using \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    336\u001B[0m                    \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMissing columns: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmissing_cols\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    337\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pre_astype_generator:\n\u001B[1;32m    338\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pre_astype_generator\u001B[38;5;241m.\u001B[39mtransform(X)\n",
      "\u001B[0;31mKeyError\u001B[0m: \"128 required columns are missing from the provided dataset to transform using AutoMLPipelineFeatureGenerator. Missing columns: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127']\""
     ]
    }
   ],
   "source": [
    "feature_importance_df = predictor.feature_importance(test_dataset_td)\n",
    "feature_importance_df[\"p_value\"].mean()\n",
    "feature_importance_df[\"p_value\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
