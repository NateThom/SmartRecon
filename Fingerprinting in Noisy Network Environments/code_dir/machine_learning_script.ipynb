{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "from statistics import mean\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import ensemble\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    cross_validate,\n",
    ")\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.ioff()\n",
    "%matplotlib inline\n",
    "\n",
    "from utils import get_dataset_parameterized"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "experiment_type = int(\n",
    "    input(\n",
    "        \"Select one of the following: \\n1. Nilsimsa Per-Packet Devices \\n\"\n",
    "        \"2. Nilsimsa Per-Packet Categories \\n3. Nilsimsa Identical Devices \\n\"\n",
    "        \"4. SimHash Identical Devices \\n5. 100x Noise\"\n",
    "    )\n",
    ")\n",
    "if not experiment_type in [1, 2, 3, 4, 5]:\n",
    "    raise ValueError(\n",
    "        \"'experiment_type' selection must be one of the following values: 1, 2, 3, 4 or 5.\"\n",
    "    )\n",
    "\n",
    "if experiment_type == 1:\n",
    "    csv_output_name = \"nilsimsa_per-packet_devices.csv\"\n",
    "    performance_visualization_df = pd.DataFrame(\n",
    "        columns=[\"C_UC\", \"noise\", \"acc\", \"bal_acc\", \"f1\"]\n",
    "    )\n",
    "    experiment_type_params = list(itertools.repeat(1, 12))\n",
    "    c_uc_params = list(itertools.repeat(1, 6)) + list(itertools.repeat(2, 6))\n",
    "    noise_params = [1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6]\n",
    "    device_params = list(itertools.repeat(-1, 12))\n",
    "    i_ni_params = list(itertools.repeat(-1, 12))\n",
    "    accum_params = list(itertools.repeat(-1, 12))\n",
    "    window_params = list(itertools.repeat(-1, 12))\n",
    "    combo_params = list(itertools.repeat(-1, 12))\n",
    "elif experiment_type == 2:\n",
    "    csv_output_name = \"nilsimsa_per-packet_categories.csv\"\n",
    "    performance_visualization_df = pd.DataFrame(\n",
    "        columns=[\"C_UC\", \"noise\", \"acc\", \"bal_acc\", \"f1\"]\n",
    "    )\n",
    "    experiment_type_params = list(itertools.repeat(2, 12))\n",
    "    c_uc_params = list(itertools.repeat(1, 6)) + list(itertools.repeat(2, 6))\n",
    "    noise_params = [1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6]\n",
    "    device_params = list(itertools.repeat(-1, 12))\n",
    "    i_ni_params = list(itertools.repeat(-1, 12))\n",
    "    accum_params = list(itertools.repeat(-1, 12))\n",
    "    window_params = list(itertools.repeat(-1, 12))\n",
    "    combo_params = list(itertools.repeat(-1, 12))\n",
    "elif experiment_type == 3:\n",
    "    csv_output_name = \"nilsimsa_identical-devices.csv\"\n",
    "    performance_visualization_df = pd.DataFrame(\n",
    "        columns=[\"C_UC\", \"device\", \"I_NI\", \"acc\", \"bal_acc\", \"f1\"]\n",
    "    )\n",
    "    experiment_type_params = list(itertools.repeat(3, 12))\n",
    "    c_uc_params = [1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2]\n",
    "    noise_params = list(itertools.repeat(-1, 12))\n",
    "    device_params = (\n",
    "        list(itertools.repeat(1, 4))\n",
    "        + list(itertools.repeat(2, 4))\n",
    "        + list(itertools.repeat(3, 4))\n",
    "    )\n",
    "    i_ni_params = [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2]\n",
    "    accum_params = list(itertools.repeat(-1, 12))\n",
    "    window_params = list(itertools.repeat(-1, 12))\n",
    "    combo_params = list(itertools.repeat(-1, 12))\n",
    "else:\n",
    "    device = int(input(\"Select one of the following: \\n1. Plug \\n2. Bulb \\n3. Cam\"))\n",
    "    if not device in [1, 2, 3]:\n",
    "        raise ValueError(\n",
    "            \"'device' parameter must be one of the following values: 1, 2 or 3. 1 represents plugs, 2 \"\n",
    "            \"represents light bulbs and 3 represents cameras.\"\n",
    "        )\n",
    "    if device == 1:\n",
    "        device_selection = \"plug\"\n",
    "    elif device == 2:\n",
    "        device_selection = \"light\"\n",
    "    else:\n",
    "        device_selection = \"cam\"\n",
    "    csv_output_name = f\"flexhash_identical-devices_{device_selection}.csv\"\n",
    "    performance_visualization_df = pd.DataFrame(\n",
    "        columns=[\"C_UC\", \"accum\", \"window\", \"combo\", \"acc\", \"bal_acc\", \"f1\"]\n",
    "    )\n",
    "    experiment_type_params = list(itertools.repeat(4, 96))\n",
    "    c_uc_params = list(itertools.repeat(1, 48)) + list(itertools.repeat(2, 48))\n",
    "    noise_params = list(itertools.repeat(1, 96))\n",
    "    if device_selection == \"plug\":\n",
    "        device_params = list(itertools.repeat(1, 96))\n",
    "    elif device_selection == \"light\":\n",
    "        device_params = list(itertools.repeat(2, 96))\n",
    "    else:\n",
    "        device_params = list(itertools.repeat(3, 96))\n",
    "    i_ni_params = list(itertools.repeat(1, 96))\n",
    "    accum_params = (\n",
    "        list(itertools.repeat(128, 12))\n",
    "        + list(itertools.repeat(256, 12))\n",
    "        + list(itertools.repeat(512, 12))\n",
    "        + list(itertools.repeat(1024, 12))\n",
    "        + list(itertools.repeat(128, 12))\n",
    "        + list(itertools.repeat(256, 12))\n",
    "        + list(itertools.repeat(512, 12))\n",
    "        + list(itertools.repeat(1024, 12))\n",
    "    )\n",
    "    window_params = (\n",
    "        list(itertools.repeat(4, 3))\n",
    "        + list(itertools.repeat(5, 4))\n",
    "        + list(itertools.repeat(6, 5))\n",
    "        + list(itertools.repeat(4, 3))\n",
    "        + list(itertools.repeat(5, 4))\n",
    "        + list(itertools.repeat(6, 5))\n",
    "        + list(itertools.repeat(4, 3))\n",
    "        + list(itertools.repeat(5, 4))\n",
    "        + list(itertools.repeat(6, 5))\n",
    "        + list(itertools.repeat(4, 3))\n",
    "        + list(itertools.repeat(5, 4))\n",
    "        + list(itertools.repeat(6, 5))\n",
    "        + list(itertools.repeat(4, 3))\n",
    "        + list(itertools.repeat(5, 4))\n",
    "        + list(itertools.repeat(6, 5))\n",
    "        + list(itertools.repeat(4, 3))\n",
    "        + list(itertools.repeat(5, 4))\n",
    "        + list(itertools.repeat(6, 5))\n",
    "        + list(itertools.repeat(4, 3))\n",
    "        + list(itertools.repeat(5, 4))\n",
    "        + list(itertools.repeat(6, 5))\n",
    "        + list(itertools.repeat(4, 3))\n",
    "        + list(itertools.repeat(5, 4))\n",
    "        + list(itertools.repeat(6, 5))\n",
    "    )\n",
    "    combo_params = [\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        6,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        6,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        6,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        6,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        6,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        6,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        6,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        6,\n",
    "    ]\n",
    "\n",
    "dataset_params = zip(\n",
    "    experiment_type_params,\n",
    "    c_uc_params,\n",
    "    noise_params,\n",
    "    device_params,\n",
    "    i_ni_params,\n",
    "    accum_params,\n",
    "    window_params,\n",
    "    combo_params,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 4, 1, 1, 3, 1, 128, 4, 2\n",
      "Dataset Name: SimHash-cam-accum_128-window_4-combo_2-cleaned\n",
      "*** Dataset Loaded ***\n",
      "Accuracy: 0.11557368151720501\n",
      "F1: 0.10987295081845125\n",
      "Accuracy: 0.1359498813714392\n",
      "F1: 0.13300301830872463\n",
      "\n",
      "____________________\n",
      "\n",
      "2. 4, 1, 1, 3, 1, 128, 4, 3\n",
      "Dataset Name: SimHash-cam-accum_128-window_4-combo_3-cleaned\n",
      "*** Dataset Loaded ***\n",
      "Accuracy: 0.11625598957929505\n",
      "F1: 0.10844274991944819\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [10], line 59\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model_name, model \u001B[38;5;129;01min\u001B[39;00m models:\n\u001B[1;32m     56\u001B[0m     \u001B[38;5;66;03m# print(f\"*** Begin Training and Evaluating {model_name} ***\")\u001B[39;00m\n\u001B[1;32m     57\u001B[0m     start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m---> 59\u001B[0m     \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     60\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(x_test)\n\u001B[1;32m     61\u001B[0m     y_probas \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict_proba(x_test)\n",
      "File \u001B[0;32m~/anaconda3/envs/simhash/lib/python3.10/site-packages/sklearn/ensemble/_stacking.py:584\u001B[0m, in \u001B[0;36mStackingClassifier.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    582\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_le \u001B[38;5;241m=\u001B[39m LabelEncoder()\u001B[38;5;241m.\u001B[39mfit(y)\n\u001B[1;32m    583\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_le\u001B[38;5;241m.\u001B[39mclasses_\n\u001B[0;32m--> 584\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_le\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/simhash/lib/python3.10/site-packages/sklearn/ensemble/_stacking.py:232\u001B[0m, in \u001B[0;36m_BaseStacking.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    227\u001B[0m         cv\u001B[38;5;241m.\u001B[39mrandom_state \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mRandomState()\n\u001B[1;32m    229\u001B[0m     fit_params \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    230\u001B[0m         {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msample_weight\u001B[39m\u001B[38;5;124m\"\u001B[39m: sample_weight} \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    231\u001B[0m     )\n\u001B[0;32m--> 232\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    233\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcross_val_predict\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    234\u001B[0m \u001B[43m            \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    235\u001B[0m \u001B[43m            \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    236\u001B[0m \u001B[43m            \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    237\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    238\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmeth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    239\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfit_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    241\u001B[0m \u001B[43m            \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    242\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    243\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmeth\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mall_estimators\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstack_method_\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    244\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m!=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdrop\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[1;32m    245\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    247\u001B[0m \u001B[38;5;66;03m# Only not None or not 'drop' estimators will be used in transform.\u001B[39;00m\n\u001B[1;32m    248\u001B[0m \u001B[38;5;66;03m# Remove the None from the method as well.\u001B[39;00m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstack_method_ \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    250\u001B[0m     meth\n\u001B[1;32m    251\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m (meth, est) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstack_method_, all_estimators)\n\u001B[1;32m    252\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m est \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdrop\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    253\u001B[0m ]\n",
      "File \u001B[0;32m~/anaconda3/envs/simhash/lib/python3.10/site-packages/joblib/parallel.py:1061\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1058\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1060\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1061\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1062\u001B[0m \u001B[38;5;66;03m# Make sure that we get a last message telling us we are done\u001B[39;00m\n\u001B[1;32m   1063\u001B[0m elapsed_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_time\n",
      "File \u001B[0;32m~/anaconda3/envs/simhash/lib/python3.10/site-packages/joblib/parallel.py:938\u001B[0m, in \u001B[0;36mParallel.retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    936\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    937\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msupports_timeout\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m--> 938\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(\u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    939\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    940\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(job\u001B[38;5;241m.\u001B[39mget())\n",
      "File \u001B[0;32m~/anaconda3/envs/simhash/lib/python3.10/site-packages/joblib/_parallel_backends.py:542\u001B[0m, in \u001B[0;36mLokyBackend.wrap_future_result\u001B[0;34m(future, timeout)\u001B[0m\n\u001B[1;32m    539\u001B[0m \u001B[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001B[39;00m\n\u001B[1;32m    540\u001B[0m \u001B[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001B[39;00m\n\u001B[1;32m    541\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 542\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    543\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CfTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    544\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/simhash/lib/python3.10/concurrent/futures/_base.py:453\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[1;32m    451\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[0;32m--> 453\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_condition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001B[1;32m    456\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n",
      "File \u001B[0;32m~/anaconda3/envs/simhash/lib/python3.10/threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 320\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for experiment_type, c_uc, noise, device, i_ni, accum, window, combo in dataset_params:\n",
    "    count += 1\n",
    "    print(\n",
    "        f\"{count}. {experiment_type}, {c_uc}, {noise}, {device}, {i_ni}, {accum}, {window}, {combo}\"\n",
    "    )\n",
    "    if c_uc == 2:\n",
    "        continue\n",
    "\n",
    "    dataset, name_of_current_data = get_dataset_parameterized(\n",
    "        experiment_type, c_uc, noise, device, i_ni, accum, window, combo\n",
    "    )\n",
    "\n",
    "    print(f\"Dataset Name: {name_of_current_data}\")\n",
    "\n",
    "    # print(f\"*** Total samples in {name_of_current_data}: {len(dataset.index)} ***\")\n",
    "    # for device_name in dataset[\"class\"].unique():\n",
    "    #     num_samples = len((dataset[dataset[\"class\"] == device_name]).index)\n",
    "    #     print(f\"*** Samples for device: {device_name} in {name_of_current_data}: {num_samples} ({num_samples/dataset.shape[0]}%) ***\")\n",
    "\n",
    "    # x is the entire dataframe except for the class column\n",
    "    x = dataset.drop([\"class\"], axis=1)\n",
    "\n",
    "    # y_original is an unaltered list of all values in the class column\n",
    "    y_original = dataset[\"class\"].values.tolist()\n",
    "\n",
    "    # y is a dataframe of only the class column and the values have been converted to numeric representation\n",
    "    y = dataset[\"class\"]\n",
    "    counter = 0\n",
    "    y_temp = dataset[\"class\"].tolist()\n",
    "    for unique_value in sorted(y.unique()):\n",
    "        for index, value in enumerate(y):\n",
    "            if value == unique_value:\n",
    "                y_temp[index] = counter\n",
    "        counter += 1\n",
    "    dataset[\"class\"] = y_temp\n",
    "    y = dataset[\"class\"]\n",
    "    labels_numeric = dataset[\"class\"].unique()\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x.values, y.values, test_size=0.2, stratify=y.values\n",
    "    )\n",
    "\n",
    "    del dataset\n",
    "    del y_original\n",
    "    del y_temp\n",
    "    del labels_numeric\n",
    "    collected = gc.collect()\n",
    "    # print(\"Garbage collector: collected %d objects.\" % (collected))\n",
    "\n",
    "    print(\"*** Dataset Loaded ***\")\n",
    "\n",
    "    models = []\n",
    "    models.append((1, ensemble.HistGradientBoostingClassifier()))\n",
    "    models.append(\n",
    "        2,\n",
    "    )\n",
    "    # models.append((2, ensemble.StackingClassifier(estimators=[(\"Ada\", ensemble.AdaBoostClassifier()), (\"HistGrad\", ensemble.HistGradientBoostingClassifier())], final_estimator=ensemble.HistGradientBoostingClassifier(), n_jobs=-1)))\n",
    "\n",
    "    # evaluate each model\n",
    "    for model_name, model in models:\n",
    "        # print(f\"*** Begin Training and Evaluating {model_name} ***\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_probas = model.predict_proba(x_test)\n",
    "        total_accuracy = accuracy_score(y_test, y_pred)\n",
    "        total_f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "        print(f\"Accuracy: {total_accuracy}\")\n",
    "        print(f\"F1: {total_f1}\")\n",
    "\n",
    "        # ******************** #\n",
    "        # Cross Validation\n",
    "        # ******************** #\n",
    "        # cv_num = 7\n",
    "        # if noise == 1 or noise == 2:\n",
    "        #     cross_val_results = cross_validate(model, x.values, y.values, cv=cv_num,\n",
    "        #                                        scoring=['accuracy', 'balanced_accuracy', 'f1_weighted'], n_jobs=1)\n",
    "        # else:\n",
    "        #     cross_val_results = cross_validate(model, x.values, y.values, cv=cv_num,\n",
    "        #                                        scoring=['accuracy', 'balanced_accuracy', 'f1_weighted'], n_jobs=-1)\n",
    "        # print(f\"*** Finished Training and Evaluating {model_name} ***\")\n",
    "        # print(f\"Dataset Name: {name_of_current_data}\")\n",
    "        # print(f\"Runtime: {time.time() - start_time}\")\n",
    "        # print(f\"Accuracy: {round(mean(cross_val_results['test_accuracy']), 4)}\")\n",
    "        # print(f\"Balanced Accuracy: {round(mean(cross_val_results['test_balanced_accuracy']), 4)}\")\n",
    "        # print(f\"F1: {mean(cross_val_results['test_f1'])}\")\n",
    "        # print(f\"Weighted F1: {round(mean(cross_val_results['test_f1_weighted']), 4)}\")\n",
    "\n",
    "        # if experiment_type == 1 or experiment_type == 2:\n",
    "        #     performance_visualization_df.loc[count] = [int(c_uc==1), noise, round(mean(cross_val_results['test_accuracy']), 4), round(mean(cross_val_results['test_balanced_accuracy']), 4), round(mean(cross_val_results['test_f1_weighted']), 4)]\n",
    "        # elif experiment_type == 3:\n",
    "        #     performance_visualization_df.loc[count] = [int(c_uc==1), device, i_ni, round(mean(cross_val_results['test_accuracy']), 4), round(mean(cross_val_results['test_balanced_accuracy']), 4), round(mean(cross_val_results['test_f1_weighted']), 4)]\n",
    "        # else:\n",
    "        #     performance_visualization_df.loc[count] = [int(c_uc==1), accum, window, combo, round(mean(cross_val_results['test_accuracy']), 4), round(mean(cross_val_results['test_balanced_accuracy']), 4), round(mean(cross_val_results['test_f1_weighted']), 4)]\n",
    "\n",
    "    print()\n",
    "    print(\"____________________\")\n",
    "    print()\n",
    "\n",
    "# performance_visualization_df.to_csv(f\"../results/{csv_output_name}\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# performance_visualization_df.to_csv(\"../figures/performance/{device_selection}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [4], line 28\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# plt.ioff()\u001B[39;00m\n\u001B[1;32m     26\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_line_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmatplotlib\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minline\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 28\u001B[0m device \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSelect one of the following: \u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m1. Plug \u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m2. Bulb \u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m3. Cam\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m device \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m]:\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdevice\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m parameter must be one of the following values: 1, 2 or 3. 1 represents plugs, 2 \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     31\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrepresents light bulbs and 3 represents cameras.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "from statistics import mean\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import ensemble\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    cross_validate,\n",
    ")\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.ioff()\n",
    "%matplotlib inline\n",
    "\n",
    "device = int(input(\"Select one of the following: \\n1. Plug \\n2. Bulb \\n3. Cam\"))\n",
    "if not device in [1, 2, 3]:\n",
    "    raise ValueError(\n",
    "        \"'device' parameter must be one of the following values: 1, 2 or 3. 1 represents plugs, 2 \"\n",
    "        \"represents light bulbs and 3 represents cameras.\"\n",
    "    )\n",
    "if device == 1:\n",
    "    device_selection = \"plug\"\n",
    "elif device == 2:\n",
    "    device_selection = \"light\"\n",
    "else:\n",
    "    device_selection = \"cam\"\n",
    "csv_output_name = f\"flexhash_identical-devices_{device_selection}.csv\"\n",
    "performance_visualization_df = pd.read_csv(f\"../results/{csv_output_name}\", header=0)\n",
    "plt.set_cmap(\"tableau-colorblind10\")\n",
    "plt.rcParams[\"grid.color\"] = (0, 0, 0, 1)\n",
    "\n",
    "performance_visualization_df_cleaned = performance_visualization_df[\n",
    "    performance_visualization_df[\"C_UC\"] == 1.0\n",
    "]\n",
    "cmap = matplotlib.colormaps[\"Blues\"]\n",
    "norm = matplotlib.colors.Normalize(\n",
    "    vmin=performance_visualization_df_cleaned[\"bal_acc\"].min(),\n",
    "    vmax=performance_visualization_df_cleaned[\"bal_acc\"].max(),\n",
    ")\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax.view_init(6, 90)\n",
    "ax.set_facecolor(\"white\")\n",
    "ax.scatter(\n",
    "    performance_visualization_df_cleaned[\"accum\"].values,\n",
    "    performance_visualization_df_cleaned[\"window\"].values,\n",
    "    performance_visualization_df_cleaned[\"combo\"].values,\n",
    "    marker=\"o\",\n",
    "    c=performance_visualization_df_cleaned[\"bal_acc\"].values,\n",
    "    s=25,\n",
    "    edgecolor=\"black\",\n",
    "    depthshade=False,\n",
    "    alpha=1,\n",
    ")\n",
    "ax.set_xlabel(\"Accumulator\")\n",
    "ax.set_ylabel(\"Window\")\n",
    "ax.set_zlabel(\"Combo\")\n",
    "ax.set_xticks([128, 256, 512, 1024])\n",
    "ax.set_yticks([4, 5, 6])\n",
    "ax.set_zticks([2, 3, 4, 5, 6])\n",
    "ax.tick_params(axis=\"x\", labelsize=8)\n",
    "ax.tick_params(axis=\"y\", labelsize=8)\n",
    "ax.tick_params(axis=\"z\", labelsize=8)\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "fig.colorbar(sm)\n",
    "title_string = f\"{device_selection} performance - Cleaned\"\n",
    "plt.title(title_string[0].upper() + title_string[1:], fontsize=16)\n",
    "plt.savefig(\n",
    "    f\"../figures/performance/{device_selection}_Cleaned_accumView.png\", dpi=1200\n",
    ")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax.view_init(6, 5)\n",
    "ax.set_facecolor(\"white\")\n",
    "ax.scatter(\n",
    "    performance_visualization_df_cleaned[\"accum\"].values,\n",
    "    performance_visualization_df_cleaned[\"window\"].values,\n",
    "    performance_visualization_df_cleaned[\"combo\"].values,\n",
    "    marker=\"o\",\n",
    "    c=performance_visualization_df_cleaned[\"bal_acc\"].values,\n",
    "    s=25,\n",
    "    edgecolor=\"black\",\n",
    "    depthshade=False,\n",
    "    alpha=1,\n",
    ")\n",
    "ax.set_xlabel(\"Accumulator\")\n",
    "ax.set_ylabel(\"Window\")\n",
    "ax.set_zlabel(\"Combo\")\n",
    "ax.set_xticks([128, 256, 512, 1024])\n",
    "ax.set_yticks([4, 5, 6])\n",
    "ax.set_zticks([2, 3, 4, 5, 6])\n",
    "ax.tick_params(axis=\"x\", labelsize=4)\n",
    "ax.tick_params(axis=\"y\", labelsize=8)\n",
    "ax.tick_params(axis=\"z\", labelsize=8)\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "fig.colorbar(sm)\n",
    "title_string = f\"{device_selection} performance - Cleaned\"\n",
    "plt.title(title_string[0].upper() + title_string[1:], fontsize=16)\n",
    "plt.savefig(\n",
    "    f\"../figures/performance/{device_selection}_cleaned_windowView.png\", dpi=1200\n",
    ")\n",
    "\n",
    "plt.rcParams[\"grid.color\"] = (0, 0, 0, 1)\n",
    "\n",
    "performance_visualization_df_uncleaned = performance_visualization_df[\n",
    "    performance_visualization_df[\"C_UC\"] == 0.0\n",
    "]\n",
    "cmap = matplotlib.colormaps[\"Blues\"]\n",
    "norm = matplotlib.colors.Normalize(\n",
    "    vmin=performance_visualization_df_uncleaned[\"bal_acc\"].min(),\n",
    "    vmax=performance_visualization_df_uncleaned[\"bal_acc\"].max(),\n",
    ")\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax.view_init(6, 90)\n",
    "ax.set_facecolor(\"white\")\n",
    "ax.scatter(\n",
    "    performance_visualization_df_uncleaned[\"accum\"].values,\n",
    "    performance_visualization_df_uncleaned[\"window\"].values,\n",
    "    performance_visualization_df_uncleaned[\"combo\"].values,\n",
    "    marker=\"o\",\n",
    "    c=performance_visualization_df_uncleaned[\"bal_acc\"].values,\n",
    "    s=25,\n",
    "    edgecolor=\"black\",\n",
    "    depthshade=False,\n",
    "    alpha=1,\n",
    ")\n",
    "ax.set_xlabel(\"Accumulator\")\n",
    "ax.set_ylabel(\"Window\")\n",
    "ax.set_zlabel(\"Combo\")\n",
    "ax.set_xticks([128, 256, 512, 1024])\n",
    "ax.set_yticks([4, 5, 6])\n",
    "ax.set_zticks([2, 3, 4, 5, 6])\n",
    "ax.tick_params(axis=\"x\", labelsize=8)\n",
    "ax.tick_params(axis=\"y\", labelsize=8)\n",
    "ax.tick_params(axis=\"z\", labelsize=8)\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "fig.colorbar(sm)\n",
    "title_string = f\"{device_selection} performance - Uncleaned\"\n",
    "plt.title(title_string[0].upper() + title_string[1:], fontsize=16)\n",
    "plt.savefig(\n",
    "    f\"../figures/performance/{device_selection}_uncleaned_accumView.png\", dpi=1200\n",
    ")\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax.view_init(6, 5)\n",
    "ax.set_facecolor(\"white\")\n",
    "ax.scatter(\n",
    "    performance_visualization_df_uncleaned[\"accum\"].values,\n",
    "    performance_visualization_df_uncleaned[\"window\"].values,\n",
    "    performance_visualization_df_uncleaned[\"combo\"].values,\n",
    "    marker=\"o\",\n",
    "    c=performance_visualization_df_uncleaned[\"bal_acc\"].values,\n",
    "    s=25,\n",
    "    edgecolor=\"black\",\n",
    "    depthshade=False,\n",
    "    alpha=1,\n",
    ")\n",
    "ax.set_xlabel(\"Accumulator\")\n",
    "ax.set_ylabel(\"Window\")\n",
    "ax.set_zlabel(\"Combo\")\n",
    "ax.set_xticks([128, 256, 512, 1024])\n",
    "ax.set_yticks([4, 5, 6])\n",
    "ax.set_zticks([2, 3, 4, 5, 6])\n",
    "ax.tick_params(axis=\"x\", labelsize=4)\n",
    "ax.tick_params(axis=\"y\", labelsize=8)\n",
    "ax.tick_params(axis=\"z\", labelsize=8)\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "fig.colorbar(sm)\n",
    "title_string = f\"{device_selection} performance - Uncleaned\"\n",
    "plt.title(title_string[0].upper() + title_string[1:], fontsize=16)\n",
    "plt.savefig(\n",
    "    f\"../figures/performance/{device_selection}_uncleaned_windowView.png\", dpi=1200\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
